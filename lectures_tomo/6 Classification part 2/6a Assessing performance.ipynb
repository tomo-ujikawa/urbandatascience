{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4995c060",
   "metadata": {},
   "source": [
    "# Module 6. Classification part 2\n",
    "# Assessing performance\n",
    "## Lecture objectives\n",
    "\n",
    "1. Understand different ways to assess the predictive accuracy of a model\n",
    "\n",
    "In the last lecture, we learned how to estimate a random forests model. But we skimmed over how to assess its predictive performance. \n",
    "\n",
    "First, let's recreate the same model we estimated before. Because we are using the `random_state` parameter, we should get exactly the same results as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the dataframe, including dummies\n",
    "joinedDf = pd.read_pickle('../scratch/joined_permits.pandas')\n",
    "dummies1 = pd.get_dummies(joinedDf.UseType, prefix='usetype_')  # creates a dataframe of dummies\n",
    "dummies2 = pd.get_dummies(joinedDf.UseDescription, prefix='usedesc_')\n",
    "joinedDf = joinedDf.join(dummies1).join(dummies2) \n",
    "xvars = (dummies1.columns.tolist() + dummies2.columns.tolist() + \n",
    "            ['YearBuilt1', 'Units1', 'Bedrooms1', 'Bathrooms1', 'SQFTmain1', 'Roll_LandValue', \n",
    "             'Roll_ImpValue', 'Roll_LandBaseYear', 'Roll_ImpBaseYear', 'CENTER_LAT', 'CENTER_LON' ])\n",
    "yvar = 'hasADU'\n",
    "df_to_fit = joinedDf[xvars+[yvar]].dropna()\n",
    "\n",
    "# test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_to_fit[xvars], df_to_fit[yvar], test_size = 0.25, random_state = 1)\n",
    "\n",
    "# estimate and fit the model\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 1, n_jobs=-1) # n_jobs uses all your computer's cores\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff30f0-4faa-479f-8315-fd835b19f2e7",
   "metadata": {},
   "source": [
    "Let's also re-estimate the more simplified version of the model. That's because the real value of these performance assessments is to compare models - which predicts best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79bfc5c-522e-4234-a2ac-3fc512c16078",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvars2 = ['SQFTmain1', 'Roll_LandValue', 'Roll_ImpValue']\n",
    "\n",
    "# create a dataframe with no NaNs\n",
    "df_to_fit2 = joinedDf[xvars2+[yvar]].dropna()\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    df_to_fit2[xvars2], df_to_fit2[yvar], test_size = 0.25, random_state = 1)\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators = 50, random_state = 1)\n",
    "rf2.fit(X_train2, y_train2)\n",
    "y_pred2 = rf2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acbb39-16c4-43aa-b0f9-50647a4d5d62",
   "metadata": {},
   "source": [
    "Last time we predicted that 0.1% of the parcels would have an ADU (0.06% in the stripped down, simplified model). Let's confirm we get the same overall prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3fb3b2-e297-4553-9d7d-1b2c6555deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted fraction True: {:.4f}. Actual fraction True: {:.4f}'.format(\n",
    "    y_pred.mean(), y_test.mean()))\n",
    "\n",
    "print('\\nSimplified model:\\nPredicted fraction True: {:.4f}. Actual fraction True: {:.4f}'.format(\n",
    "    y_pred2.mean(), y_test2.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df69713",
   "metadata": {},
   "source": [
    "Let's look more formally at the predictive accuracy.\n",
    "\n",
    "`scikit-learn` has several useful functions here:\n",
    "* The [*confusion matrix*](https://en.wikipedia.org/wiki/Confusion_matrix) gives the number of observations that fall into each predicted and actual category (e.g is True and predicted to be True - a \"true positive\")\n",
    "* The [*accuracy score*](https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score) gives the fraction of accurate predictions. A high score is no guarantee of a good model. Suppose you want to predict whether a person will be struck by lightening tomorrow. Then just predict \"No\" for everyone. Accurate, but not useful!\n",
    "* The [*classification report*](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report) reports key metrics for each category (in this case, `True` and `False`. *Precision* gives the fraction of true positives compared to the number of predicted positives (TP / (TP + FP) - basically, how many of our positive predictions are correct. *Recall* gives the fraction of true positives compared to the number of actual positives (TP / (TP + FN) - basically, what proportion of the positives did we correctly predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "confusion_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430dcfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score: {:.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5167f73",
   "metadata": {},
   "source": [
    "We can also plot the confusion matrix. Note the colorbar shows the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b7c910-30a3-402e-b8f6-ddb63bb57011",
   "metadata": {},
   "source": [
    "How does this compare to our simplified model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc70c67-bfe3-4ee6-8dbf-28473b869239",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test2, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98231cc",
   "metadata": {},
   "source": [
    "So our model complex model does a bit better. In particular, we do a much better job in getting the true positives. \n",
    "\n",
    "It's still not great. But this is not surprising: ADU construction will depend on many factors that are outside our dataset: lot shape, the ability of the owners to afford an ADU, and their personal circumstances (e.g. having an elderly family member). Bringing in census data and other predictors might help.\n",
    "\n",
    "But even if the predictions are not always accurate, the predicted *probabilities* can be informative. We could even map them to indicate where ADUs are likely to be built. \n",
    "\n",
    "We can access the probabilities from the `rf` object. Note it gives us a matrix: the first column is the probability of `False`, and the second is the probability of `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48374fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ed6bc-3fd4-4044-9c1d-eddc31d71762",
   "metadata": {},
   "source": [
    "Also note that we want to have the predicted probabilities of *all* the parcels - the test and the training datasets.\n",
    "\n",
    "So we can concatenate the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83307286-740b-477d-a2a7-4d2f195871ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict_proba(pd.concat([X_test,X_train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1baa99",
   "metadata": {},
   "source": [
    "It's easy to turn an array like this into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "predictions = pd.DataFrame(rf.predict_proba(pd.concat([X_test,X_train])), \n",
    "                           columns = ['pred_noADU', 'pred_ADU'])\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ebbe5e",
   "metadata": {},
   "source": [
    "Let's join our original test data back to these predictions. \n",
    "\n",
    "One wrinkle: we just have an integer index on `predictions`. Does this match `X_test`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf64ae",
   "metadata": {},
   "source": [
    "No, that has the original `APN` index. Fortunately, `reset_index()` will change the index to a sequential integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= predictions.join(pd.concat([X_test,X_train]).reset_index())\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d79a73e",
   "metadata": {},
   "source": [
    "Now, let's map these predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c933a0-e2e8-42cf-be26-1ad7c6a9229f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Convert your dataframe, <strong>predictions</strong> to a GeoDataFrame that includes a geometry column.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "predictions = gpd.GeoDataFrame(predictions, \n",
    "                    geometry = gpd.points_from_xy(\n",
    "                        predictions.CENTER_LON, \n",
    "                        predictions.CENTER_LAT, crs='EPSG:4326'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77cf61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "predictions.to_crs('EPSG:3857').plot('pred_ADU', markersize=0.001, ax=ax)\n",
    "ctx.add_basemap(ax=ax)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d97786",
   "metadata": {},
   "source": [
    "Actually, this map says more about where parcels overlap rather than the presence of an ADU. There are a couple of strategies that we might use to avoid this:\n",
    "* Don't plot parcels with less than a certain probability of having an ADU\n",
    "* Use a different colormap (the `cmap` argument)\n",
    "* Use a smaller marker size (to avoid some overlap) (the `markersize` argument)\n",
    "* Scale the colormap so that it tops out at a lower value (the `vmax` argument)\n",
    "\n",
    "Let's try the first and fourth approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c613e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "predictions[predictions.pred_ADU>0.1].to_crs('EPSG:3857').plot('pred_ADU', cmap='Purples', markersize=0.001, \n",
    "                                     vmax=0.2, ax=ax, legend=True)\n",
    "ctx.add_basemap(ax=ax, alpha = 0.3)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf46316-19df-45c5-8565-c9188f5a36b6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Experiment with different values for <strong>vmax</strong>. What does this parameter do?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171874e1-8b08-40e3-8a7c-d3ff14b64dc0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> What other colormaps can you use? Explore the matplotlib documentation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d588742b",
   "metadata": {},
   "source": [
    "Hmm. Maybe changing the marker size is a better way to go than a color.\n",
    "\n",
    "We can do this by scaling the column that we plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions['pred_ADU_scaled'] = predictions.pred_ADU*0.01\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "predictions[predictions.pred_ADU>0.1].to_crs('EPSG:3857').plot(cmap='Purples', \n",
    "                                     markersize='pred_ADU_scaled', \n",
    "                                     ax=ax, legend=True)\n",
    "ctx.add_basemap(ax=ax, alpha=0.4)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b6cd7",
   "metadata": {},
   "source": [
    "It's still not clear how to distinguish areas with lots of parcels from areas with few parcels but a high propensity to have an ADU. Any ideas? \n",
    "\n",
    "We'll leave the mapping here, but my inclination would be to aggregate to a grid or to census block groups, in order to make the propensity to have an ADU a bit clearer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93785bc8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Key Takeaways</h3>\n",
    "<ul>\n",
    "  <li>Confusion matrices are an excellent way to assess predictive performance, particularly for binary outcomes.</li>\n",
    "  <li>Mapping and other descriptive plots are also good ways to explore the outputs.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
