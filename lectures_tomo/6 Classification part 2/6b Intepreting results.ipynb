{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4995c060",
   "metadata": {},
   "source": [
    "# Interpreting results\n",
    "## Lecture objectives\n",
    "\n",
    "1. Explore how to interpret a random forests model\n",
    "2. Show how to report feature importances\n",
    "3. Explore the use of partial dependence plots\n",
    "\n",
    "We'll continue with our same example of ADUs in Los Angeles.\n",
    "\n",
    "First, we'll recreate the same random forests model as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the dataframe, including dummies\n",
    "joinedDf = pd.read_pickle('../scratch/joined_permits.pandas')\n",
    "dummies1 = pd.get_dummies(joinedDf.UseType, prefix='usetype_')  # creates a dataframe of dummies\n",
    "dummies2 = pd.get_dummies(joinedDf.UseDescription, prefix='usedesc_')\n",
    "joinedDf = joinedDf.join(dummies1).join(dummies2) \n",
    "xvars = (dummies1.columns.tolist() + dummies2.columns.tolist() + \n",
    "            ['YearBuilt1', 'Units1', 'Bedrooms1', 'Bathrooms1', 'SQFTmain1', 'Roll_LandValue', \n",
    "             'Roll_ImpValue', 'Roll_LandBaseYear', 'Roll_ImpBaseYear', 'CENTER_LAT', 'CENTER_LON' ])\n",
    "yvar = 'hasADU'\n",
    "df_to_fit = joinedDf[xvars+[yvar]].dropna()\n",
    "\n",
    "# test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_to_fit[xvars], df_to_fit[yvar], test_size = 0.25, random_state = 1)\n",
    "\n",
    "# estimate and fit the model\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 1, n_jobs=-1) # n_jobs uses all your computer's cores\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc306b3c",
   "metadata": {},
   "source": [
    "### Feature importances\n",
    "In a regression model, the size of the coefficient is a good guide to how important a factor is in determining the outcome.\n",
    "\n",
    "In a random forests setting, the equivalent concept is *feature importance*. It is often measured through \"mean decrease in impurity\" (MDI). The meaning of MDI is beyond our scope here, but you can interpret feature importance as \"how much does a variable improve our predictions.\" \n",
    "\n",
    "The importances are accessed from the `feature_importances_` property of the `rf` object. [The `scikit-learn` docs provide easy-to-implement examples](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html), which we'll follow here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a1062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# convert to a series, and give the index labels from our X_train dataframe\n",
    "forest_importances = pd.Series(importances, index=X_train.columns)\n",
    "\n",
    "# get the standard deviations to be able to plot the error bars\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "# plot importances\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052df79a",
   "metadata": {},
   "source": [
    "So we see that only a few variables are driving the results.\n",
    "\n",
    "The bar chart is pretty bad. We have a few options:\n",
    "* Make a larger plot with horizontal bars, so that the text is easier to read\n",
    "* Only plot the most important features\n",
    "* Use an interactive tool where you can hover over the bar. The `plotly` and `mplcursors` libraries are two options here.\n",
    "\n",
    "Let's try the first option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025091c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use seaborn rather than matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# sort the importances in descending order\n",
    "forest_importances.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,15))\n",
    "sns.barplot(x=forest_importances.values, y=forest_importances.index, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d92328-cef2-4334-ac79-f78a9adcb61d",
   "metadata": {},
   "source": [
    "We can see that the value of the land and the improvements on the lot, the location (latitude and longitude), size, and year built are the most predictive factors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501c77ef-8afd-4df2-9435-5e94757baee9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Redo this plot with only the 10 most important features.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2575e",
   "metadata": {},
   "source": [
    "## Partial dependence plots\n",
    "The feature importances are very useful in highlighting the variables that have a large impact on the predictions.\n",
    "\n",
    "However, there's one key limitation: they don't tell us the direction of the impact. Does a larger lot make an ADU more or less likely to be built?\n",
    "\n",
    "There are several ways to examine directionality. One approach is called \"SHAP plots\" - [here's a detailed explanation.](https://towardsdatascience.com/introduction-to-shap-with-python-d27edc23c454) I find the beeswarm plots to be most useful, as in my [paper with Nazanin Rezaei](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0278265) where we look at the relationship between urban form, PM2.5 emissions, and access to green space.\n",
    "\n",
    "Here, we'll look at a simpler way to examine directionality - **partial dependence plots**. In effect, these show the impact of one variable on your outcome, holding all other variables constant. The [scipy documentation is here](https://scikit-learn.org/stable/modules/partial_dependence.html). \n",
    "\n",
    "The `PartialDependenceDisplay` is the relevant function. You need to specify the `features` argument - i.e., which variables are going to be plotted. This takes an integer (the order of your features), a variable name, or a list.\n",
    "\n",
    "For example, suppose we want to plot the impact of `YearBuilt1`. (Note that this can be slow.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ecf85-57c9-45a4-82e8-3df966e5007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "PartialDependenceDisplay.from_estimator(rf, X_test,\n",
    "                                       ['YearBuilt1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888aed1c-ede4-4ee5-b2e5-59386f1262e5",
   "metadata": {},
   "source": [
    "Or let's look at the top 3 features, per our feature importances analysis above.\n",
    "\n",
    "Remember, we already stored these in `forest_importances`, and sorted them by importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568af813-f947-4840-a514-60b07ef70150",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe52fd-89c9-4a1b-9f8f-8fbd9eca6bde",
   "metadata": {},
   "source": [
    "So we can get the top 3 from the index of `forest_importances`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46536c3-32c1-4901-9580-4b10e923318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_importances.index[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf77c4d-078e-46e1-9fb9-d40a13e8f59e",
   "metadata": {},
   "source": [
    "And pass them to `PartialDependenceDisplay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546a655-a87a-4a3c-bea9-46a81f0a5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "PartialDependenceDisplay.from_estimator(rf, X_test,\n",
    "                                       forest_importances.index[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93785bc8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Key Takeaways</h3>\n",
    "<ul>\n",
    "  <li>Feature importance is a way of showing which variables matter in your model.</li>\n",
    "  <li>However, they don't tell you the directionality - does an increase in one variable increase or reduce the outcome probability. For that, a partial dependence plot is useful.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
