{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sunrise-lease",
   "metadata": {},
   "source": [
    "# Parsing craigslist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1dfbf1",
   "metadata": {},
   "source": [
    "## Lecture objectives\n",
    "\n",
    "1. Provide more practice with scraping web pages and parsing text\n",
    "2. Show how to handle errors (\"exceptions\") gracefully\n",
    "3. Provide more pratice with `pandas` and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-watts",
   "metadata": {},
   "source": [
    "Let's continue with the craigslist example from the previous lecture.\n",
    "\n",
    "We've already figured out how to extract the information from a single post. Now, let's try and get all 120 posts from the first page of listings, and put them in a `pandas` dataframe. \n",
    "\n",
    "`pandas` can create a dataframe from many different data structures. But one of the easiest ways to is to create a list of dictionaries, and then tell `pandas` to convert that into a dataframe. \n",
    "\n",
    "Each element of the list will be a craigslist post. Within that list element, we have a dictionary of columns.\n",
    "\n",
    "First of all, let's recreate the list of posts as before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a69779",
   "metadata": {},
   "source": [
    "Remember that `posts` held our list of posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('../data/cl_posts.html', 'r') as f:  \n",
    "    saved_content = f.read()\n",
    "        \n",
    "soup = BeautifulSoup(saved_content, features='html.parser')\n",
    "posts = soup.find_all('li', class_='cl-search-result')\n",
    "print(len(posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e199e9fd-8629-4842-8531-9e35c7e47b41",
   "metadata": {},
   "source": [
    "This is the code we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6713cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posts[2].find(class_='titlestring').text)\n",
    "print(posts[2].find(class_='titlestring')['href'])\n",
    "print(posts[2].find(class_='meta').text.split('路')[1])\n",
    "print(posts[2].find(class_= 'priceinfo').text)\n",
    "print(posts[2].find(class_= 'post-bedrooms').text)\n",
    "print(posts[2].find(class_= 'post-sqft').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55720210",
   "metadata": {},
   "source": [
    "So now, let's do the same to all posts. We will:\n",
    "* Loop over the list, `posts`\n",
    "* Use the code above to extract each element we want, and store it in a dictionary\n",
    "* Create a list of these dictionaries, that we can then turn into a dataframe\n",
    "\n",
    "Note that rather than printing each result, we'll assign it to a temporary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "postList = [] # empty list that we can append to. This will be our list of dictionaries\n",
    "\n",
    "for post in posts:\n",
    "    # create temporary variables with the attributes that we extract from each post\n",
    "    title = post.find(class_='titlestring').text\n",
    "    url = post.find(class_='titlestring')['href']\n",
    "    neighborhood = post.find(class_='meta').text.split('路')[1]\n",
    "    price = post.find(class_= 'priceinfo').text\n",
    "    br = post.find(class_= 'post-bedrooms').text\n",
    "    sf = post.find(class_= 'post-sqft').text\n",
    "\n",
    "    # put them all in a dictionary\n",
    "    postDict = {'title': title, 'url':url, 'neighborhood':neighborhood, \n",
    "                'price':price, 'br':br, 'sf':sf}\n",
    "    \n",
    "    # append that dictionary to our list\n",
    "    postList.append(postDict)\n",
    "    \n",
    "# turn the list into a dataframe\n",
    "df = pd.DataFrame(postList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bfb0f2",
   "metadata": {},
   "source": [
    "### Catching exceptions\n",
    "What went wrong? Let's unpack this error.\n",
    "\n",
    "It looks like we couldn't get our `br` variable, because there was no text.\n",
    "\n",
    "So what if we back up and see what that object looks like, before we try and get the text? Note that `post` will still contain the element of the `posts` list where the error occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "post.find(class_= 'post-bedrooms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b6373",
   "metadata": {},
   "source": [
    "Nothing! How come?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b694f",
   "metadata": {},
   "source": [
    "Aha. It's a `None` object - basically empty. And so we can't ask to get the text where nothing exists.\n",
    "\n",
    "How can we be more robust to these errors (technically, \"exceptions\")?\n",
    "\n",
    "One way is to use `try...except`. We `try` a block of code, and if something goes wrong, we execute the alternative code under `except`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe73192",
   "metadata": {},
   "outputs": [],
   "source": [
    "postList = [] # empty list that we can append to. This will be our list of dictionaries\n",
    "\n",
    "for post in posts:\n",
    "    try:\n",
    "        # create temporary variables with the attributes that we extract from each post\n",
    "        title = post.find(class_='titlestring').text\n",
    "        url = post.find(class_='titlestring')['href']\n",
    "        neighborhood = post.find(class_='meta').text.split('路')[1]\n",
    "        price = post.find(class_= 'priceinfo').text\n",
    "        br = post.find(class_= 'post-bedrooms').text\n",
    "        sf = post.find(class_= 'post-sqft').text\n",
    "\n",
    "        # put them all in a dictionary\n",
    "        postDict = {'title': title, 'url':url, 'neighborhood':neighborhood, \n",
    "                    'price':price, 'br':br, 'sf':sf}\n",
    "    \n",
    "        # append that dictionary to our list\n",
    "        postList.append(postDict)\n",
    "    except: # we could also be more specific, e.g. except AttributeError:\n",
    "        # this is only excecuted if the code under try fails\n",
    "        # if there's a problem, we'll just append an empty dictionary\n",
    "        postList.append({})\n",
    "    \n",
    "# turn the list into a dataframe\n",
    "df = pd.DataFrame(postList)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27d213",
   "metadata": {},
   "source": [
    "So we find the errant rows - 0, 1, and lots of others.\n",
    "\n",
    "The `try...except` syntax is useful, but a blunt instrument. Notice that we lose all the data for that posting, not just the housing size.\n",
    "\n",
    "As an alternative, we could explicitly check for missing data at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "postList = [] # empty list that we can append to. This will be our list of dictionaries\n",
    "\n",
    "for post in posts:\n",
    "    title = post.find(class_='titlestring').text\n",
    "    url = post.find(class_='titlestring')['href']\n",
    "    neighborhood = post.find(class_='meta').text.split('路')[1]\n",
    "    price = post.find(class_= 'priceinfo').text\n",
    "    br_tmp = post.find(class_= 'post-bedrooms')\n",
    "    if br_tmp is None:\n",
    "        br = None\n",
    "    else:\n",
    "        br = br_tmp.text\n",
    "    \n",
    "    # we can also have our if..else statements as a one-liner\n",
    "    sf_tmp = post.find(class_= 'post-sqft')\n",
    "    sf = None if sf_tmp is None else sf_tmp.text\n",
    "\n",
    "    # put them all in a dictionary\n",
    "    postDict = {'title': title, 'url':url, 'neighborhood':neighborhood, \n",
    "                'price':price, 'br':br, 'sf':sf}\n",
    "    \n",
    "    # append that dictionary to our list\n",
    "    postList.append(postDict)\n",
    "    \n",
    "df = pd.DataFrame(postList)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd04e7",
   "metadata": {},
   "source": [
    "Notice that we got some partial data for these rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-edward",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Now let's plot the distribution of price. A box plot would be a good choice here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot('price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1d7f29",
   "metadata": {},
   "source": [
    "Oops. What went wrong? \n",
    "\n",
    "The error message isn't terribly helpful, so let's look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db480863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e259f259",
   "metadata": {},
   "source": [
    "Aha. We can't do a boxplot of a string! So let's convert it to a number. This is a three-stage process:\n",
    "* Remove the `$` (replace `$` with an empty string)\n",
    "* Do the same for the `,`\n",
    "* Convert to a float. The pandas `astype` function is useful here.\n",
    "\n",
    "Let's do this and store the output in a new column, `price_numeric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_numeric'] = df.price.str.replace('$','').str.replace(',','').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a0612-4308-4577-8a2c-4f050aad1cd4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Convert the sf and br fields to numeric in the same way.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d3832-bb4a-4fe1-91da-bf3ccb26361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplicity, I'll just write over the old column name rather than create \n",
    "# new columns sf_numeric and br_numeric\n",
    "\n",
    "df['sf'] = df.sf.str.replace('ft2','').astype(float)\n",
    "df['br'] = df.br.str.replace('br','').astype(float)\n",
    "df[['sf','br']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df.boxplot('price_numeric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ef7cc",
   "metadata": {},
   "source": [
    "We can also break it out by neighborhood using the `by` argument.\n",
    "\n",
    "But what's the problem here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot('price_numeric', by='neighborhood')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ea2ec",
   "metadata": {},
   "source": [
    "There are several ways to examine the contents of a pandas DataFrame column. `unique()` can be useful.\n",
    "\n",
    "Here, we see that there isn't a fixed set of neighborhood names, and so further cleaning would be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f427798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.neighborhood.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ec802",
   "metadata": {},
   "source": [
    "What about the relationship between prices and the apartment size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ade1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot('sf', 'price_numeric', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-environment",
   "metadata": {},
   "source": [
    "So now we've created a dataframe that extracts all the posts on the first page! \n",
    "\n",
    "There's still quite a bit to do. For example:\n",
    "\n",
    "* We only have one page, and it would be useful to get data from the subsequent pages\n",
    "* Our neighborhood field is really dirty, so it's hard to do any mapping\n",
    "* We don't have any information about parking\n",
    "* We don't have the geographic coordinates (lat/lon)\n",
    "\n",
    "But let's leave those for future work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-boring",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Key Takeaways</h3>\n",
    "<ul>\n",
    "  <li>Scraping unstructured webpages involves more detective work and trial and error.</li>\n",
    "  <li>Some will have a consistent format and helpful class codes and html tags. Some won't.</li>\n",
    "  <li>Your code will need to be robust to missing fields and other inconsistencies in page formatting.</li>\n",
    "  <li>Be nice! You may need to slow the pace of your requests down.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
