{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sunrise-lease",
   "metadata": {},
   "source": [
    "# Scraping craigslist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1dfbf1",
   "metadata": {},
   "source": [
    "## Lecture objectives\n",
    "\n",
    "1. Explore scraping more complex web pages\n",
    "2. Show how to use classes to extract web content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-watts",
   "metadata": {},
   "source": [
    "## Example: Scraping craigslist data\n",
    "Craiglist provides a wealth of information on apartment rentals and other types of housing, as you can read about in the [Boeing and Waddell paper](https://journals.sagepub.com/doi/abs/10.1177/0739456X16664789). But short of clicking through lots of links, how do we access it?\n",
    "\n",
    "As with any scraping project, the first step is to get an example web page, and see if we can reverse-engineer the structure.\n",
    "\n",
    "One option is to parse each detailed post, with information on parking, desired qualities of roommates, etc. But a lot of information is actually in the [list of posts](https://losangeles.craigslist.org/search/apa#search=1~list~0~0). \n",
    "\n",
    "Until late 2022, it was a pretty straightforward process to use `requests` to retrieve the list of posts. However, craigslist recently changed their web pages to use JavaScript, which means that the method using `requests` no longer works. There are workarounds, but to keep things simple, let's just download it to our computer using a web browser. This is a great illustration of some of the hazards of web scraping - there is no guarantee that the website owner won't suddenly change the structure on you!\n",
    "\n",
    "In Chrome, you download as a \"web page, complete.\" That will give you a `html` document and a folder with other files. You'll just need the `html` file, which I saved to our git repository as `cl_posts.html`.\n",
    "\n",
    "We can open the file in Python using the `read()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-maker",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('../data/cl_posts.html', 'r') as f:  \n",
    "    saved_content = f.read()\n",
    "        \n",
    "soup = BeautifulSoup(saved_content, features='html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-pricing",
   "metadata": {},
   "source": [
    "Let's look at the output to figure out how to parse it.\n",
    "\n",
    "Again, this takes some detective work and trial and error. As we saw before, opening up the page in the Develop mode in your web browser is often the simplest way to see the hierarchical tag struture.\n",
    "\n",
    "It looks like each post is in a `<li>` tag. Moreover, note that it's also in a `class` called `cl-search-result`. Structured data like this make it much easier to scrape! The `find_all()` function takes an optional `class_` argument that can filter by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = soup.find_all('li', class_='cl-search-result')\n",
    "\n",
    "# Note that there are 120 results, which is the number of posts returned on the Craigslist webpage. \n",
    "# That's a good sign!\n",
    "print(len(posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c085c0",
   "metadata": {},
   "source": [
    "Let's look at a sample post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef2e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-colors",
   "metadata": {},
   "source": [
    "Again, we could use the Develop mode within a web browser to try and reverse-engineer the structure, although this is a short enough snippet that we can just look at this text.\n",
    "\n",
    "It looks like the title is in a class called `titlestring`, along with the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35e93a-6d96-42c8-aead-3a947fe1a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[2].find(class_='titlestring')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563545d-1fd0-4fdc-b9dc-0d6e0a5baef5",
   "metadata": {},
   "source": [
    "So the title is in the text, and the URL is an attribute called `href`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0e4c0-7de4-48ad-bd5a-debb4fec8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posts[2].find(class_='titlestring').text)\n",
    "print(posts[2].find(class_='titlestring')['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae0341e-3c8f-48fb-8fe8-b1082d72e0a1",
   "metadata": {},
   "source": [
    "What about the other information? The neighborhood seems to be within a tag called `meta`. Note that `find` just finds the first occurence. `find_all` finds all of them, and returns a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733cd37-4c36-4f99-914d-45331a7e73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[2].find(class_='meta').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754d7a5-4e48-41f4-83c4-793412e84eb8",
   "metadata": {},
   "source": [
    "This is a bit annoying to separate out, but we can use the dots and split on these using `str.split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041eace0-6a52-4e8d-807e-c818bab6f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "'Splitting this sentence into words'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02224110-f56a-443d-9bed-9f6c91f84821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with a separator that isn't a space\n",
    "'Splitting this sentence into words'.split('i')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d0586e-ee7f-4db3-b548-83238a6c38e7",
   "metadata": {},
   "source": [
    "Here, we want to split on the dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f879d6-026a-4f52-a084-c33a7e22a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[2].find(class_='meta').text.split('·')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155d1cc-fffb-4720-b4f0-01606fa9b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's the second element\n",
    "posts[2].find(class_='meta').text.split('·')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707eb044",
   "metadata": {},
   "source": [
    "The price, number of bedrooms, and square footage are easier to find, as they are in their own dedicated classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posts[2].find(class_= 'priceinfo').text)\n",
    "print(posts[2].find(class_= 'post-bedrooms').text)\n",
    "print(posts[2].find(class_= 'post-sqft').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-romania",
   "metadata": {},
   "source": [
    "Now we understand the structure of each page. So we are ready to put all of the posts in a dataframe. We'll do that in the next lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-boring",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Key Takeaways</h3>\n",
    "<ul>\n",
    "  <li>Scraping unstructured webpages involves more detective work and trial and error.</li>\n",
    "  <li>Some will have a consistent format and helpful class codes and html tags. Some won't.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
